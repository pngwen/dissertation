\documentclass[../dissertation.tex]{subfiles}

\begin{document}

\chapter{Introduction}
\begin{quote}
\textit{Nam cum pictor praecogitat quae facturus est, habet quidem in
intellectu sed nondum intelligit esse quod nondum fecit.}

-- Anselm of Canterbury~\cite{anselm}
\end{quote}
In the eleventh century, Anselm of Canterbury wrote what has since
come to be known as the ontological argument for the existence of
God~\cite{anselm}.  Anselm's argument was based on the assumption that
all ideas, or more specifically, all thoughts originate either from
perceptions of the outside world or from images formed within the
imagination.  From this he provides an argument for the existence of
a divine being.  The research presnted here follows this same
epistemologcal assumption to a much less trivial end.
Instead of proving divine influence, the present work shall attempt to
measure the influence present in the written works of less divine beings.

The basic assumption made about text documents is the same assumption
that Anselm made about the origin of thoughts.  Every word, phrase,
sentence, paragraph, and theme in a document must come from one of two
sources.  Either the author created the thought from within their own
mind, and as such this counts as a literary contribution, or the
author could have transferred ideas from some outside source.  These
sources can take on many forms.  In the case of academic writing, the
author is likely to have been influenced primarily by the various
books and papers that they have read over the course of their
research.  Of course, another form of influence is a coauthor (though
in the case of academic literature, coauthors are almost always
explicitly stated.)  Of course, the influence over the text in a paper
is not constrained merely to the literature that the author has cited,
but is ultimately a reflection of an author's entire life experience
and background.  In the case of literary writing, such as a novel or
play, a reasonable assumption is that an author is influenced by other
works within their genre as well as by the society in which they live.

Given that every written document is influenced by at least a small
set of outside documents, the present work attempts to model and
quantify this influence by separating documents into a set of factors
and then searching for common factors among the documents.  The
desired result has two parts.  First, a weight is assigned to each
factor indicating its importance in the target work.  Second, the
factors themselves should carry enough semantic meaning to identify
the ideas and elements of style which have been transferred from a
source document to a target document.  Thus, the goal of the present
work is to identify influencing factors and to quantify the influence
they exert on a target document.

The usefulness of such a measurement should be readily apparent to
anyone working in any academic field.  In modern research, the
perofrmance of participants is rooted in an attempt to measure that
person's influence over their chosen field.  Traditional approaches to
this problem involve counting citations over a specific window of time
~\cite{adler2009} while more modern approaches tend to involve some
document semantics~\cite{dietz2007, jiang2014} Measuring
influence in a written document can also be applied in situations
where authorship is in question.  Given a corpus of works of confirmed
provenance, and a disputed document, influence modelling can identify
the possible influence of each author.  Thus textual influence
modelling can be used to answer the question of authorship where it is
disputed, or could potentially be used to identify plagearised
passages.


\section{Modeling Influence}
At a high level, an influence model identifies elements that appear to
have been incorporated into a target document from a source document.
These elements can take on many forms.  For example, they could
include elements of style, topics, phrases, or ideas.  A human reader
seems to be able to identify these elements on an intuitive level, as
can be seen readily whenever a reader says one author ``sounds like''
another.  This operation is also in effect when tracing ideas through
written academic literature.  In either case, the text of a traget
document along with its corpus of cited documents seems to provide
sufficient evidence to identify potential sources of influence in the
target document.

The cief problem with an intuitive model such as the one outline in
the last paragaraphy is that it is highly subjective.  Every
conclusion reaching by human scholars in such a system must appeal to
intuition and logic, and so determining the strength of any perceived
relationships present in the corpus presents a difficult challenge.
In recent years, the emerging field of computational stylistics has
offered several techniques for quntifying these elements of style
which can serve as markers of influence~\cite{bader2007, craig2009,
  burrows2017}.  In so much as it can, computational stylistics has
the principal goal of using textual evidence to answer the question of
authorship.  The current state of the art techniques for addressing
these questions rely upon statistical analysis of word frequencies
within documents~\cite{craig2009}.  The typical
approach is to use a set of ``marker words'' to determine the
likeliehood of an author's contribution to a target document.  Those
words that are more likely to occur in the works of one author are
ascribed to them if there is sufficient statistical significance of
the word's classifying power.  This current approach offers only a
coarse level of determination.  Computational stylistic analysts can
identify words that are more likely to come from one author's work,
and they in turn identify whether that author appears to have
contributed to a target document.  Thus the current techniques only
inform the probability of an author's contribution as a dichotomy.
Each potential author was either a contributor, or they were not.  The
objective of the model outlined in this dissertation is to extend this
model to include more detail.  As opposed to determining whether an
author has contributed to a target work directly, this model assumes
that influence is present in multiple forms.  Instead, the present
model seeks to identify the strength of influence, as well as to
identify what those specific influences were.

\subsection{Modeling Documents as Tensors}
In order to analyze a document, it must be first quantified in some
way that allows for analysis.  The model discussed in this
dissertation represents documents using tensors.  The term tensor has
been broadly applied across multiple fields to describe several
different types of related objects.  For the purposes of factor
analysis, a tensor is simply an extension of matrices into a higher
number of modes. In tensor terminology a ``mode'' is a dimension along
the tensor which can be indexed.  A scalar is a mode zero tensor, a
vector is a mode one tensor, and a matrix is a mode two tensor.  When
the number of modes exceeds two, it is customary to refer to the array
simply as a tensor.  A detailed account of the tensor operations
performed by this model is given in the next chapter.  For a complete
treatment of tensors as they pertain to factor analysis, see Tamara
Kolda's tutorial~\cite{kolda2006}.

The text documents to be analyzed are represented as a tensor by
dividing them into phrases of length $n$.  These phrases, commonly
referred to as $n$-grams, are counted and their frequencies are
entered into a tensor.  Each word in the corpus vocabulary is assigned
an index, and the tensors $n$ modes refer to these indexes.  For
example, suppose $n=3$.  The document tensor $\mathcal{D}$ would have
3 modes.  The entry $\mathcal{D}_{ijk}$ refers to the frequency of the
$n$-gram consisting of words $i$, $j$, and $k$ from the corpus
vocabulary.  Modeling documents in this way allows for phrases of any
length to be studied.

The underlying principle of tensor analysis is polyadic decomposition,
which was first descrbied by Frank Hitchcock in
1927~\cite{hitchcock1927}.  When a tensor is expressed in polyadic
form, it is expressed as the sum of the outer product of mode 1
tensors.  (This is also referred to as the tensor product of vectors,
which is in line with the geometric interpretation of tensors as the
outer product of vector spaces.)  Each polyadic factor in a tensor of
$m$ modes is the tensor product of $m$ vectors.  For example, given a
3 mode tensor $\mathcal{T} \in \mathbb{R}^{i\times j \times k}$, its
polyadic decomposition into $r$ factors is a set of factors which
satisfies Equation~\ref{eq:polyadic_decomposition}.

\begin{equation} \label{eq:polyadic_decompositon}
  \mathcal{T} = \displaystyle\sum_{i=1}^{r} a_i \otimes b_i \otimes c_i
\end{equation}

Hitchcock's paper mainly presents the polyadic decomposition from a
purely mathematical perspective, with applications to studying tensor
invariants and tensor rank.  In fact, as later papers show, the
problem of determining the rank of a tensor is
NP-Complete~\cite{haastad1990}.  Polyadic decomposition began to see
other uses when it was rediscovered in 1970 by Richard
Harshman~\cite{harshman1970}, Douglas Carroll, and Jih-Jie
Chang~\cite{carroll1970}.   Harshman coins the term ``PARAFAC'', a
portmanteau of ``Parallell Factors'' while Caroll and Chang refer to
the model as ``CANDECOMP'' in placed of ``Canonical Decomposition''.
Both papers present the model as a means of studying psychological
data by treating the tensor factors as explanatory variables for the
variance in the tensor data.  In recent years, tensor analysis has
began to take root in other fields such as chemometrics~\cite{bro1997}
and text mining~\cite{bader2007}.  




\subsection{Modeling Influence}
The basic model applied to the document begins with the decomposition
of a document into its individual factor tensors.

\begin{equation} \label{eq:document_decomposition}
  \mathcal{D} = \sum f_i 
\end{equation}

Where $f_i\in F$ is a factor of the tensor $\mathcal{D}$.  As is usually
the case with tensor factors, the model becomes more expressive by
separating out a normalizing value $\lambda_i$ from each $f_i$.  Thus
the decomposed document becomes:

\begin{equation} \label{eq:document_decomposition_normal}
  \mathcal{D} = \sum \lambda_i f'_i
\end{equation}

Where $f'_i=\frac{1}{|f_i|} f_i$ and $\lambda_i = |f_i|$.  This is
desirable for two reasons.  First, $\lambda_i$ identifes the magnitude
of the factor, and therefore indicates the factors importance in the
target document.  Second, this leaves $f'_i$ as a ``proportional
profile'' as described by Richard Harshman~\cite{harshman1970} . As
will soon become apparent, this proportional representation of the
factors is ciritical for the proper functioning of this tensor based
model of influence.

Let $C$ be a corpus of documents, encoded as tensors $\mathcal{D}_j
\in C$.  Let $\mathcal{D}_t$ be the target document to be studied, and
all other documents in $S=C - \mathcal{D}_t$ are treated as source
documents for $\mathcal{D}_t$.  The goal of the influence model is to
ascribe the factors of $\mathcal{D}_t$ to a factor from the source
documents $\mathcal{D}_s$ and assign weights to each of the documents
influences. Each document in $C$ is decomposed as per
equation~\ref{eq:document_decomposition_lambda}.  $\mathcal{D}_t$ is
also decomposed into its components.  This produces $F'_s$ and
$\Lambda_s$ for the source docuements as well as $F'_t$ and $Lambda_t$
for the target document.  By measuring the similarity of each factor
$f'_t$ and source factors $f'_s$, each factor can be ascribed to a
source document $\mathcal{D}_s$ or as being original to
$\mathcal{D}_t$.

Hence, the decomposition of the target document can be rewritten:

\begin{equation} \label{eq:influence_factors}
  \mathcal{D}_t = \sum f_{ts} + f_{tt}
\end{equation}

Normalizing as in the previous equations, the target
document's decomposition becomes:

\begin{equation} \label{eq:influence_factors_normalized}
  \mathcal{D}_t = \sum \lambda_{ts} f'_{ts} + \lambda_{tt} f_{tt}
\end{equation}

Given these new factors, the influence of each document is extracted:

\begin{equation} \label{eq:document_lambda}
  \Lambda_t = (\lambda_1, \lambda_2, \ldots \lambda_n, \lambda_t)
\end{equation}

Weights for each document are then extracted as their proportion of
importance to the target document.

\begin{equation} \label{eq:document_weights}
  W = \displaystyle\frac{1}{|\Lambda_t|} \Lambda_t
\end{equation}

\section{Related Work}

\section{Outline of this Dissertation}

\section{Bibliography (temporarily in each chapter)}
\bibliographystyle{unsrt}
\bibliography{../sources}
\end{document}
