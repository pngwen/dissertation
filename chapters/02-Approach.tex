\documentclass[../ut-dissertation.tex]{subfiles}
\begin{document}
\input{commands}

\chapter{Approach}
This chapter details the approach used to build the influence model
for a target document and its corpus of supporting documents.  This
chapter also covers details of implementing this model and the
challenges inherent in realizing this model.  The first section of
this chapter outlines the various steps required to build the
influence model.  This is followed by implementation challenges and
details, and then the chapter concludes with a simple example of the
model's application.

\section{Influence Modeling}
The influence model is governed by a document list and a set of
parameters.  The inputs to the model are outlined described in
Table~\ref{table:modelInput}.  The document list contains a list of all
of the documents in the corpus.  The document list contains potential
source documents and one target document.  The target document is
placed at the end of the document list by convention.
\begin{table}
  \begin{tabular}{ll}
    \hline
    $docs$ & A list of documents in the corpus.  The target document\\
           & is the final entry in the list. \\
    $nfactors$ & The number of factors for tensor decomposition.\\
    $z^*$ & The critical value for significance testing.\\
    \hline
  \end{tabular}
  \caption{Model Input}
  \label{table:modelInput}
\end{table}

The generated model's output consists of the set of factors which have
been found to influence the target document, the weights of each
document's influence on the target document, and the set of factors
found from the decomposition of the document tensors.  The output variables of
the generated model are described in Table~\ref{table:modelOutput}.
\begin{table}
  \begin{tabular}{ll}
    \hline
    $\set{W}$ & Set of weights of each factor of the target document.\\
              & $\set{W}_i$ is the weight of target document factor $i$.\\
    $\set{S}$ & The set of soure indexes for each factor.\\
              & $\set{S}_i$ is the index of the source factor, 0 \\
              & if the factor is unique to the target document.\\
    $\set{F}$ & The set of all document factor tensors.\\
    \hline
  \end{tabular}
  \caption{Model Output}
  \label{table:modelOutput}
\end{table}

\subsection{Approach Overview}
The overall process was described in Chapter 1.  What remains is to
see the detailed formulation of how each component of the model is
computed.  The overall algorithm is described in
Algorithm~\ref{alg:model}.  
\begin{algorithm}
  \caption{Influence Model Construction}
  \label{alg:model}

  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwFunction{Prepare}{prepare}
  \SetKwFunction{BuildVocabulary}{build\_vocabulary}
  \SetKwFunction{BuildTensor}{build\_tensor}
  \SetKwFunction{ExtractFactors}{extract\_factors}
  \SetKwFunction{DistanceMatrix}{build\_distance\_matrix}
  \SetKwFunction{ExtractInfluence}{extract\_influence}
  \SetKwData{W}{$\set{W}$} \SetKwData{S}{$\set{S}$}
  \SetKwData{D}{$\tens{D}$}
  \SetKwData{V}{$\set{V}$} \SetKwData{LN}{$\set{\Lambda}$}
  \SetKwData{F}{$\set{F}$} \SetKwData{DM}{$M$}
  \SetKwData{C}{$\set{C}$}
  
  \Input{$docs$, $nfactors$, $z^*$}
  \Output{\W, \S, \F}
  \BlankLine
  \Prepare{$docs$}\;
  \V $\leftarrow$ \BuildVocabulary{$docs$}\;
  \C $\leftarrow\emptyset$\;
  \ForEach{$d$ in $docs$}{
    \D$ \leftarrow$ \BuildTensor($d$, $\set{V}$)\;
    $\C \leftarrow \C \cup \{\D\}$\;
  }
  \LN,\F $\leftarrow$ \ExtractFactors{\C, $nfactors$}\;
  \DM $\leftarrow$ \DistanceMatrix{\F}\;
  $\lambda \leftarrow$ the entries in \LN corresponding to the target document.\;
  \W, \S $\leftarrow$ \ExtractInfluence{$|docs|$, \DM,\F,$\lambda$}\;
  \Return{\W, \S, \F}\;
\end{algorithm}

\subsection{Document Filtering and Vocabulary Extraction}
\begin{algorithm}
  \label{alg:Prepare}
  \caption{Prepare}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \Input{$docs$}
  \Output{None}
  \BlankLine
  \ForEach{$d$ in $docs$}{
    Remove Punctation from $d$\;
    Remove Numbers from $d$\;
    Convert $d$ to lower case\;
  }
\end{algorithm}


\begin{algorithm}
  \label{alg:vocabulary}
  \caption{Build Vocabulary}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwData{V}{$\set{V}$}
  \Input{$docs$}
  \Output{\V}
  \BlankLine
  $\V\leftarrow\emptyset$\;
  \ForEach{$d$ in $docs$}{
    \ForEach{$word$ in $d$}{
      $\V \leftarrow \V \cup \{word\}$\;
    }
  }
  \Return{\V};
\end{algorithm}

\subsection{Tensor Construction}
\begin{algorithm}
  \label{alg:BuildTensor}
  \caption{Build Tensor}
  \SetKwData{D}{$\tens{D}$} \SetKwData{V}{$\set{V}$} \SetKwData{N}{$n$}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  
  \Input{$d$, \V, \N}
  \Output{\D}
  \BlankLine
  $\D \leftarrow $ Tensor with dimension $|\V| \times |\V| \ldots
  \times_n |\V|$\;
  Fill \D with 0\;
  $len \leftarrow$ number of words in $d$\;
  \For{$i \leftarrow 1 $ to $len - n$} {
    \tcc{Compute Tensor Element Index}
    $index \leftarrow$ list of $n$ integers\;
    \For{$j\leftarrow i $ to $i+n$} {
      $index[j] \leftarrow$ index of word $d[j]$ in \V\;
    }
    \BlankLine
    \tcc{Update Frequency of This $n$-gram}
    $\D[index] \leftarrow \D[index] + 1$\;
  }
  \Return{\D}
\end{algorithm}

\subsection{Tensor Decomposition}

\begin{algorithm}
  \label{alg:ExtractFactors}
  \caption{Extract Factors}
  \SetKwData{LN}{$\set{\Lambda}$}  \SetKwData{C}{$\set{C}$}
  \SetKwData{F}{$\set{F}$} \SetKwData{U}{$\set{U}$}
  \SetKwData{T}{$\tens{T}$}\SetKwData{D}{$\tens{D}$}
  \SetKwFunction{Norm}{$\mathrm{L}_1$\_norm}
  \SetKwFunction{CCD}{ccd\_ntfd}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \Input{\C, $nfactors$}
  \Output{\LN, \F}
  \BlankLine
  $\F \leftarrow \emptyset$\;
  $\LN \leftarrow \emptyset$\;
  $nmodes \leftarrow$ number of modes in $\C[1]$\;
  \ForEach{\D in \C}{
    $\U \leftarrow $ \CCD{\D, $nfactors$}\;
    \For{$i$ = 1 to $nfactors$}{
      \tcc{Build the Factor}
      $\T \leftarrow \U[1][:,i]$\;
      \For{$m$ = 2 to $nmodes$}{
        $\T \leftarrow \T \otimes \U[m][:,i]$\;
      }

      \tcc{Compute the norm and normalize the factor}
      $\lambda \leftarrow $\Norm{\T}\;
      $\T \leftarrow \T / \lambda$\;

      \tcc{Insert the factor and norm into the list}
      $\F \leftarrow \F \cup \{\T\}$\;
      $\LN \leftarrow \LN \cup \{\lambda\}$\;
    }
  }
  \Return{\LN, \F}
\end{algorithm}
  

\subsection{Factor Classification}
\begin{algorithm}
  \caption{Build Distance Matrix}
  \label{alg:distance}
  \SetKwData{DM}{$M$} \SetKwData{F}{$\set{F}$}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwFunction{Norm}{$\mathrm{L}_1$\_norm}
  \Input{\F}
  \Output{\DM}
  \BlankLine
  $\DM \leftarrow $ Matrix with dimension $|\F| \times |\F|$\;
  \For{$i=1$ to $|\F|$}{
    \For{$j=1$ to $|\F|$} {
      $\DM[i,j] \leftarrow$ \Norm{$\F[i] - \F[j]$}\;
    }
  }
  \Return{\DM}
\end{algorithm}

\subsection{Weight Assignment}
\begin{algorithm}
  \caption{Extract Influence}
  \label{alg:influence}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwData{DM}{$M$} \SetKwData{F}{$\set{F}$}
  \SetKwData{LN}{$\set{\Lambda}$}\SetKwData{Ndocs}{$ndocs$}
  \SetKwData{W}{$\set{W}$} \SetKwData{S}{$\set{S}$}
  
  \Input{\Ndocs, \DM, \F, \LN}
  \Output{\W, \S}
  \BlankLine
  \tcc{Find the critical value for hypothesis testing.}
  Compute mean, $\mu$, and standard deviation $\sigma$ of \DM
  excluding the diagonal.\; 
  $threshold \leftarrow$ Critical value given $\mu$ and $\sigma$\;
  \BlankLine
  \tcc{Compute Weights}
  $s \leftarrow \sum \LN$\;
  $\W \leftarrow \LN / s$\;
  \BlankLine
  \tcc{Classify Factors}
  $nfactors \leftarrow |\LN|$\;
  \For{$i=1$ to $nfactors$}{
    $min \leftarrow \DM[row,1]$\;
    $minIndex \leftarrow 1$\;
    $row \leftarrow i + nfactors * (ndocs-1)$\;
    \For{$j=1$ to $nfactors * ndocs$}{
      \If{\DM[row,j]$< min$}{
        $min \leftarrow \DM[row,j]$\;
        $minIndex \leftarrow j$\;
      }
    }
    \eIf{$min \leq threshold$}{
      $\S[i]\leftarrow minIndex$\;
    }{
      $\S[i]\leftarrow 0$\;
    }
  }
  \Return{\W, \S}\;
\end{algorithm}

\section{Implementation }
\section{Challenges}
\section{Implementation Details}

\section{Model Evaluation}

\section{A Simple Example}
\subsection{Source Text and Vocabulary}
\subsection{Document Tensors}
\subsection{Document Factors}
\subsection{Classification and Weights}
\end{document}
