\documentclass[12pt]{article}
\title{Literature Review Draft}
\author{Robert Lowe}
\usepackage{cite}
\usepackage{fullpage}

\begin{document}

\maketitle

\section{Introduction}
As robots encroach upon the world of men, they will all do one thing
quite frequently.  They will, in the due course of time, suffer some
sort of hardware failure.  Anyone who has worked closely with modern
robots can attest to just how fragile these mechanized monsters can
be.  Of course, the same can be said of any complex system, and the
quest for robust and fault tolerant systems has been a major pursuit
both in and out of computing.  This idea was well summarized by
Fernando Corbato ``Don't wonder if some mishap may happen, but rather
ask what one will do about it when it does occur.''  \cite{corbato}.

Accepting the truth of the ultimate fate of complex systems is what
gave rise to the field of prognostics.  However, prognostics has
traditionally focused on designing maintenance schedules and
delivering information to well trained technicians so that systems can
be repaired before catastrophic failure can occur.  This works well in
laboratory or manufacturing floor settings, but it is not a workable
solution in home and office environments where a robot must work far
away from anyone who knows how to service it.  Of course, current
trends in robotics seem to be leading towards a revolution of personal
robots, which in turn means that robots will be increasingly operating
among humans who have none of the necessary skills needed to affect
repairs should something go wrong with the system.  In extreme cases,
a robot may even be called upon to act in environments where no human
can reach them.  In either case a modern robot must be able to cope
with its own impending electromechanical damage.

The traditional approach to robust robotics, as will be explored in
detail later in this review, has been to build systems that tolerate
failures gracefully.  A modern robust robot will either use alternate
sets of controllers to continue its mission in a damaged state, or it
will use controllers that allow it degrade and cease functioning in a
way which causes no damage to other parts of its environment.  



\subsection{Prognostics}
\subsection{Robust Control Systems}
\subsection{Bipedal Walking}


\section{Prognostics}
Complex machines are of growing importance in today's world.  As people
become more and more dependent on these machines, they begin to realize a
universal truth about these machines.  Namely, these machines break.  In most
situations, a broken machine is a nuisance, but in some instances a failed
system can be catastrophic.  For instance, if we consider the control system of
a nuclear power plant or the guidance system of a spacecraft, we can easily
find that failure of such systems is unacceptable.  The main goal of
prognostics is to predict when a system failure will occur in order to inform
the maintenance process of critical systems.

This introduction to prognostics is divided into two parts.  First, we explore
the definition of the prognostic problem itself, and then we explore the
definitions of how a prognostic system can be evaluated.

\subsection{The Prognostics Problem}
Attempting to predict how long a system will remain operational is
not a new discipline.  However, the study of prognostics as its own field is a
fairly recent development~\cite{877920}.  The formalized field, which is still
emerging, was first given serious study in the aerospace industry as described
in Engel et al's paper~\cite{877920}.  Engel established the general
definition of prognostics as the capability to provide early detection of small
fault conditions and to use this information to predict the remaining useful
life of the system being observed.  

Engel points out that condition assessment, which traditionally focuses on
fault diagnostics, forms the underpinnings of condition based maintenance.  The
core aspect of conditioned based maintenance is to ensure both availability
and reliability of critical systems.  Because critical systems cannot be taken
offline at will, maintenance must only be performed when it is necessary.
Prognostic forecasting can provide an important component to the assessment of a
system's condition in that it predicts the duration between a detected fault
and the expected time of failure.  Thus an operator can determine a schedule
for a system by performing maintenance before failure occurs, but not so far in
advance as to be costly.  In order to meet this goal, however, simple
estimations of remaining useful life are insufficient.  A prognostic algorithm
must also provide a confidence measure so that its prediction can be
weighted against its expected accuracy.  Engel develops this idea by using a
probabilistic model to predict a ``Just In Time point'' which is the point
past which a failure becomes highly likely.  This point forms the optimal time
for a system to be taken offline for maintenance.  

In short, Engel et al provides a definition for basic prognostic goals and a
technique for evaluating the efficacy of any algorithm which accomplishes these
goals.  Later papers tend to develop on this definition and add details and
nuance.  For instance, Liu refers to the ``Just in Time'' point as the ``best
efficiency point'' which is a point chosen along the prognostic time line to
represent the best time for repairs~\cite{4585821}.  This is a subtle change to
the previous point in that this point is not necessarily the point at which
failure is probabilistically predicted with high confidence.  Instead, Liu's
approach takes into account risk mitigation and repair cost in order to identify
the best time for maintenance from the standpoint of both availability and cost.

Both \cite{877920} and \cite{4585821} mention the rise of sensor technology as
being crucial to the emergence of the field of prognostics.  This is largely
due to the ability of systems to have the capacity to maintain some notion of
their own operating status.  Prior to the widespread availability of good sensors,
prognostics was predominately performed by determining the mean time to failure
based on large scale sampling of system components in production.  For
instance, any automobile owner is accustomed to buying ``5-year'' versus
``3-year'' batteries.  Such determinations are made based on historical data,
and a statistical model (usually a normal distribution) of the components' life spans.
However, as pointed out in \cite{4711428}, the real world degradation of a
system usually occurs as a stochastic process.
Moreover, simple mean time to failure
computations are inadequate because failure conditions cannot be explored
exhaustively in the samples used to inform the mean time to failure model.  Thus
maintaining some sense of the state of a system or component is needed.  This
led to the emergence of a notion of a ``damage'' variable which, as described
in Peysson et. al \cite{4711428} is a measure of the deviation of a system away
from nominal operation.  Peysson summarizes the emerging trends in the
prognostic field as a hierarchy of three classes of prognostic techniques, all
of which are expressed as different forms of accounting for system damage by
dividing prognostic approaches into three categories: {\em experience base,
  data driven, and model based}.  

The lowest level technique is called {\em experience based} prognostics which
is the previously mentioned estimation of mean time to failure based on
statistical sampling of devices in operation.  Stated simply, experience based
prognostics would work by saying ``The operational life of this battery is 3
years because 90 percent of this type of battery have successfully operated for
3 years.''  Experience based prognostics is the lowest cost in terms of
complexity and materials, but this comes at a sacrifice of precision.  

Moving up the hierarchy, and building upon experience based
prognostics, is {\em data driven} prognostics.  The data driven
approach uses classification systems to create an estimation of the
machine's health based on learned trends in data.  Generally this
approach uses regression techniques (such as statistical regression or
machine learning) to learn the trends in observed data.  They also
tend to work by learning trends which represent degradation processes
in systems.  They use this data to classify a system into different
representation of varying health based on sensor data.  Data driven
systems are, according to Peysson, more precise than experience based
systems, but they come at a higher cost in terms of materials (in that
an application must have sensors to determine state) and in terms of
complexity.

The highest level of the prognostic hierarchy is {\em physical model}
prognostics.  In this approach a model of a system's performance is created by
a domain expert.  This model is then used to predict the ideal outputs of the
system for a given set of inputs.  The model's outputs are then compared to
actual sensor data to determine the state of the system.  Physical models are
generally very complex to build in that the model must not only account for the
operation of a healthy system, but must also be able to predict system
operation under degraded conditions.  Because of the complexity of constructing
the model, which are usually computationally complex, these models come at the
highest cost in terms of material and complexity.  However, a truly good
physical model will generally outperform a data driven system in terms of
precision.  

The role of prognostic systems in the maintenance cycle of complex systems is
further refined in Liu et al's paper \cite{4273732}.  This paper refines the
goals of availability and reliability by adding ``survivability'' to the mix.
The system studied by Liu in this paper is an all electric ship which is being
developed for navy service.  Clearly, in this system safety is a critical
concern.  The solutions proposed by Liu use a mixture of diagnostic and
prognostic techniques to predict and isolate failures.  The role which
prognostics plays in prediction based maintenance in this paper is part of a
larger trend where prognostics not only predicts when maintenance is necessary,
but also models what maintenance is necessary to maintain the goals of the
system.  This shift in paradigm comes with an increased demand for precision
models and forecasting capability and thus adds a new layer of complexity to the
study of prognostic systems.  

Further refinements on the definition of the prognostic problem are presented in
\cite{4585821} where another goal is added.  Namely, prognostics should be
non-intrusive and should not interfere with the core function of the system to
which it is applied.  This goal leads to a further importance of data driven
prognostics as is seen in \cite{5393625} which shows that an emerging trend is
performing prognostics using incomplete or potentially noisy data.  The reason
this data is incomplete is that having a goal of non-intrusive detection makes
parts of the system unobservable, or at least practically unobservable.

Following the above goals and definitions, a standard set of steps for
prognostic systems have emerged, as is outlined in Hall et al's
\cite{6024332}.  These essential steps are:
\begin{enumerate}
  \item Collect Sensor Data.
  \item Denoising and Data Characterization
  \item Extract features from raw data.
  \item Use extracted features to build a model
  \item use model(S) to perform PHM analysis.
\end{enumerate}
These steps show that the present trend in prognostics is toward a fusion of
model and data driven prognostics.  Namely, the model is learned and then
applied to online data readings.  This online model is in sharp contrast to the
original statistics based experience models.  Further, prognostics is now seen
in a broader sense as part of a larger system goal of Prognostic Health
Management or PHM.  The goals of PHM are to perform accurate predictions and
apply those predictions as part of the maintenance strategy of the system being
observed.  Because Hall's essential steps emerged organically in the
literature, future prognostic systems can likely be fit into this framework,
however a generalized technique for how to accomplish the PHM analysis portion
is still lacking.

\subsection{Evaluating Prognostic Algorithms}
Prognostic prediction, and its definition, are only part of the problem of
performing prediction based maintenance.  Because prognostic predictions are
stochastic, and because there exist many techniques for performing prognostics,
PHM also depends on developing methods of evaluating the efficacy of prediction
algorithms.  As mentioned in Lybeck et al's paper \cite{4161637} this is not a
trivial task.  In this paper, one of the first to provide a general approach to
evaluating prognostics, Lybeck studys a system which monitors the vibration of
a ball bearing system.  The approach Lybeck proposes is to evaluate a
prognostic algorithm by observing the predicted RUL over several time steps and
comparing it to the actual RUL for a real failure.  The quantification which
Lybeck proposes is to measure the deviation of the expected RUL from actual
RUL, and then summarizing it as a mean and standard deviation.  Thus Lybeck's
criteria for judging the accuracy of the prognostic prediction is to measure
the Gaussian noise relative to actual observed failures.  

Measuring the Gaussian noise of the predictor is, of course, a very course
measurement for the prognostic system.  Such a measure can tell whether a
prediction system is working, but it cannot determine which parts contribute to
the error rate.  A more refined approach, which is proposed by Zili and Li in
\cite{5413560}, allows for a multi-part evaluation and validation of a
prognostic health management system.  Here, Zili and Li decompose the abilities
of a prognostic system into four primary abilities:
\begin{enumerate}
  \item State Supervision
  \item Fault Diagnosis
  \item Fault Prewarning
  \item Prognosis of Remaining Life
\end{enumerate}
Note how this also reveals some details of how PHM analysis is performed, a
detail which is still presently emerging.  Zili and Li's work provide a much
finer grained analysis of the performance of a prognostic system.  In each
category, the establish a set of requirements which must be met and then
provide a quantified approach of how to analyze these requirements.  For state
supervision, they propose to monitor the rate at which the system is able to
determine its state.  For fault diagnosis, the system is judged according to
the false alarm rate and the false positive rate.  That is, the system is
metrics are the percentage of false alarms and the percentage of missed
faults.  Fault prewarning is measured in a similar fashion, using the percentage
of predicted faults which do not occur and the percentage of faults which were
not predicted.  They also introduce other parameters for measuring prewarning
related to the confidence of predictions, but their full explanation is beyond
the scope of this review.  Remaining life prognosis is again evaluated
according to the deviation between predicted RUL and actual RUL.  

In addition to providing a framework for evaluation metrics, Zili and Li also
provide a framework for how to perform validation of PHM systems.  They propose
a (fairly standard) 3 part system of evaluation using analytical evaluation,
simulation validation, and then experimental evaluation.  

In recent developments, as presented in Lume and Pylvanen \cite{6299510}, the
trend of evaluation is following the trend toward using pattern classification
as the primary means of prognostic prediction.  Here, prognostic confidence is
defined to be the probability that a labeled state belongs to the class of
states indicative of a future failure mode.  Here, more than simple deviation
is measured.  This proposed metric accounts for the classification of a
predicted failure mode, so that several can be compared.  For instance, Lume
and Pylvanen use a wind turbine system which operates in the normal state and
has 4 failure modes (one of which being ``unknown'' failure).  The prognostics
engine can predict with some level of confidence which of the 4 failures it
expects to be in at a predicted time step.  This confidence level is computed
based on statistical sampling of states on known trajectories to failure, thus
establishing both a prognostic and diagnostic confidence level.


\subsection{Application of Existing Algorithms}
As is the case with most fields, many existing algorithms can be applied to
prognostics.  Most approaches fall under the heading of either being model
based, data driven, or mixed prognostic systems.  This section explores each
kind in turn. The model based systems are very specialized and typically only
applicable to one problem domain, or possibly even to only one particular
system or device.  However, one branch of model based algorithms, statistical
models, provide techniques which are applicable to many problem domains.  The
data driven prognostics methods borrow heavily from the field of machine
learning.  Finally, the mixed approach provides a fusion of both model and data
driven techniques.

\subsubsection{Model Based Prognostics}
Model based prognostics can best be described as a system which uses a
predetermined model to predict the remaining useful life of a system or a
component within a system.  As previously discussed, these models often reflect
domain expertise and are usually difficult to derive.  However, once
discovered, a good model can create very accurate predictions of RUL.  

Model based systems in the literature can be further classified into two
subcategories.  The first, and more traditional of the two, are the physical
models.  A physical model is created by a domain expert to represent some known
and quantifiable physical aspect of the system. The second category is
comprised of the statistical model.  Here a model is created by statistical
analysis of samples of system operating data.  This approach is similar to data
driven prognostics, but still falls under the heading of being model based
because these systems never update the model.  The statistical models are
extracted by painstaking analysis by domain experts, and so they cannot be said
to be a true data driven approach as their learning is not automated.

When a system or component is modeled for the purpose of PHM, there are
two main approaches which are used.  In the first case, the system's ideal
performance is modeled, and then the deviation from this ideal performance is
measured and treated as a damage variable \cite{1569256}.  Another approach is
to model the process of failure.  That is, the system's degradation processes
are modeled and then the system's state is compared to the modeled faults.
This is the approach used in many modern statistical models \cite{4925841}.  

\subsubsection{Physical Models}
Physical models for PHM are typically created by domain experts with a single
system in mind.  Many of these models are either one-off models or are only
applicable within a very specific program domain.  For example, in
\cite{5747595} provides a very complete model based on the structural and
aerodynamic loads placed on a multistage rockets at the moment of stage
separation.  There is a very robust model, but it clearly does not readily
transfer to other problem domains.

Predictions involving the remaining useful life of bearings is a problem which
is often studied in prognostics.  Most mechanical devices contain bearings of
some sort, and they physics of bearings is well understood owing to their
frequent usage.  Several papers use models of different aspects of bearings,
such as \cite{5531344}, \cite{1656121}, and \cite{6299545}.  This last paper
could possibly be considered as a statistical model paper as it uses Gaussian
models in its RUL process.  However, the Gaussian model is augmented with an
extensive physical model, and the physical model dominates the text of the
paper.  These are just a small cross section of the vast number of papers which
present different models of mechanical bearings.

Other applications of physical models include railway systems \cite{5747204},
actuator components \cite{5979041}, and electronic devices \cite{5464512}.  In
all of these papers, a physical model which is presented which is based on the
physics of device operations, and so offer little in the way of transferable
techniques.  In some cases, such as in \cite{5979041} the model covers an
entire class of devices, but cannot transfer to another class of devices.  

Another notable development in the realm of physical models is the combination
of prognostic prediction and control theory as seen in Brown et al's paper
\cite{5547651}.  This paper uses a model of prognostic model of a degradation
process to adjust the parameters of a control model.  Thus the system becomes a
fault tolerant system, and is capable of performing accurate control under
degraded conditions.  Thus this system has two physical models, one of the
degradation process and one control model.

\subsubsection{Statistical Models}
Another approach to model based prognostics is to construct a statistical model
of some aspect of the system and use it to estimate damage and remaining useful
life.  As mentioned before, many of these models are models of degradation
processes and are used to recognize when the system has entered a sequence of
events which lead to system failure.  One such model is given in Hines and
Garvey's paper \cite{4925841}.  This paper proposes a model which is based on
finding ``general path'' between a healthy state and a failed state.  Systems
are sampled while operating in a degraded state, and then generalized paths are
generated by performing statistical regression on the degraded signals.  These
characteristic signals form the basis of the model.  To perform prediction of
RUL, an operating system's signal is compared against the extracted paths.
Once a signal has been classified as belonging to a known failure process, the
model can then project when this signal will cross a threshold indicative of
system failure.

A similar approach is used in Kim et al's \cite{5747564}. Kim's paper presents
a technique which uses regression models to extract faults in an avionics
system.  This technique uses models of avionic behavior as its input, but can
be applied to other systems as well. 

Other statistical models are more specialized.  For instance \cite{6228962}
describes a system which models imperfect repairs.  That is, this paper
presents a model of faults which are caused by faulty repairs of systems.
Another example is found in \cite{6299533} which uses a combination of PCA and
regression to model the behavior of railway systems.  The extracted model is
then used as a means to determine damage by measuring deviation from modeled
and actual system behavior.

\subsection{Data Driven Prognostics}
While model based prognostics is desirable, in many cases good models do not
exist. When this is the case, a prognostic system must learn how to identify
impending failures by observing sensor data. The typical approach to data
driven prognostics is to treat prognostics as a classification problem. Here,
the system is classified into a series of various states of health, and then
some type of regression is applied to predict when a transition from one state
to another will occur. The papers discussed in this section deal with this
learning process by applying various machine learning techniques.

Owing to the state-based nature of how prognostics is typically approached,
Hidden Markov Models are a a common way to learn and perform prognostic data as
can be seen in \cite{6246315}, \cite{6190767}, \cite{6023116}, \cite{6228954},
\cite{5414580}, \cite{5262871}, and \cite{1241660}. In these papers, the
observed signals are sent through a series of filters before being presented to
an HMM. The HMM is then used to predict the most likely chain of transitions
between the machine’s internal (hidden) health states.  Most of the papers
listed above vary only by the filtering process, and the filtering process is
tailored to to the individual problem being solved. The core of HMM based
prognostics is really the prediction of the most likely chain, and RUL is
extracted by counting the times steps until the system is expected to enter a
failure state. The literature on HMM usage for prognostics shows that it does
yield good results, but is very prone to over-fitting, and also is highly
dependent on domain knowledge in order to construct the states and identify
which states represent failures.

Another classification approach is frequently applied is the use of support
vector machines as seen in \cite{6299511}, \cite{6299512}, \cite{6228843}, and
\cite{5939470}.  In this approach, training data are classified into a series
of states, and these states are learned by SVM.  The SVM model is then used to
classify observed states.  Some form of time series regression is used to
predict the remaining useful life of the system.  The major drawback to this
approach lies in the computational complexity of the SVM.  Also, the choice of
kernel functions can have a dramatic impact on the classification accuracy of
the SVM.  

Several other machine learning approaches have been applied to prognostics with
varying results.  Artificial neural networks have been used in conjunction with
Bayesian classifiers \cite{4350749} and with support vector regression
\cite{5939530}.  In both of these cases, ANN was used to learn the parameters
to another classifier.  Another similar technique is to employee genetic
algorithms to learn the parameters for another learning algorithm as is the
case in \cite{4350749}.  All of these approaches, especially the GA approach,
showed very slow convergence, and so they are not typically employed in
prognostics.  

In summary, the machine learning techniques that have been used in prognostics
show the same drawbacks that would be expected in any machine learning
application.  Namely, convergence tends to be slow, and there is an inherent
risk of over-fitting.  What makes the prognostics problem unique is that the
acquisition of the requisite training data is typically very expensive both in
terms of time and materials.  In some cases, acquiring training data from
actual failure modes may be impossible, and so traditional training techniques
cannot be used.  The next section is about a series of approaches which
alleviate this problem.


\subsection{Mixed Approaches}
As has already been shown, both model and data driven prognostics come with
many challenges which must be overcome in order to build an effective
prediction system.  In the case of model driven prognostics, modeling the
system is very difficult because prognostics demands a system model of both
healthy and degraded systems.  Data driven prognostics is difficult because of
the expense and rarity of real failure data.  One approach which attempts to
mitigate these problems is to combine both model and data driven prognostic
techniques.  This section looks at these approaches.

One approach, as proposed by Zhang et. al in \cite{1470385} is to use a machine
learning algorithm to modify the parameters of an existing model.  The
predictor in this paper uses a stochastic model of failure processes and then
uses PCA and an HMM to modify the probabilities of this model.  The tricky part
of this scheme is that finding a model that will converge is difficult,
however, the system adapts itself to degraded processes, and so tends to not be
prone to over-fitting.  By combining 3 approaches, Zhang was able to create a
system which was robust and capable of anomaly detection, fault detection and
degradation estimation.  Also, this provided a technique of fusing learned
features and modeled features which is evident in future works.

In Zhang's approach, each step of the prediction system informs the next phase.
Another technique that has shown some success is fusing several independent
classifiers.  For instance, Goebel et. al proposed a scheme for fusing
competing predictors in \cite{1656116}.  In this paper, Goebel uses both a
physical model and a data-driven regression model.  The results are then fused
by a reasoner which uses both the variance and confidence levels of each
classifier to arrive at a weighted average of the predicted RUL.  Goebel shows
that this technique is very robust, and results in a good classifier which
outperforms each of its individual components.

More fusion techniques follow Goebel's, as is seen in \cite{6299507},
\cite{6113902}, and \cite{6024361}.  In all of these approaches, competing
models and data driven classifiers are used to arrive at a consensus of system
RUL.  All of these approaches come with increased complexity as multiple
algorithms must be execute simultaneously, however, they have been shown to
overcome limitations in incomplete physical models and the inherent problems of
data driven techniques.

\subsection{Handling Uncertainty}

\section{Robust Robot Controllers}
\subsection{Traditional Approach}
\subsection{Self Modelling Approach}
\subsection{Self-Healing Systems}

\section{Bipedal Walking}
\subsection{Dependency Chains}
\subsection{Inverted Pendulum Model}
\subsection{Parameterized Walking}

\section{Future Work}
With all of the techniques presented here, one common thread can be found.
Each of these systems predict, at a minimum, the remaining useful life of an
observed system.  Some are capable of producing anomaly detection and an
estimation of damage/health, but not all of them are.  Also, few novel
approaches to prediction exist.  Most of these systems are a combination of
classification and regression.

The work presented in this dissertation aims, in part, to address this.
Presented here is a framework which can be applied to produce any of the above
mentioned prognostic schemes, but does so in a way which facilitates fusion of
information and the estimation of anomalies, health, and remaining useful life
of the observed system.  

The work presented here also includes the use of this framework to perform
adaptive control of a system in order to extend its remaining useful life.  The
properties of the generalized framework will be necessary in order to
accomplish this task as it will provide a method for determining not only the
present health of the system, but the effects of control modification on the
system.  


\section{Bibliography}
\bibliography{papers}
\bibliographystyle{plain}

\end{document}
