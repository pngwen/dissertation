\documentclass{article}
\title{Proposal: Influence Modeling Through Tensor Decomposition}
\author{Robert Lowe}

\usepackage{epigraph}
\usepackage{cite}

%some custom tensor commands
\newcommand{\tens}[1]{\mathcal{#1}}
\newcommand{\ntens}[1]{\hat{\tens{#1}}}

\begin{document}
\maketitle

\section{Introduction}
\subsection{Impact Metrics}
The metrics used to measure the performance of an academic author are
typically based on citation counts.  Sometimes this metric is based on
the overal citation rate of journals in which pulbications appear or
they are based on per-paper citations.  As has been noted by several
uthors, such as Adler et. al~\cite{adler2009}, these meterics are
often misinterpreted or abused.  For example, Adler cites the
disparity between the rate of publication of biologists and
mathematicans as an instance in which entire disciplines are given
disparaging grades relative to another. Adler also indicates that
mereley counting citations may not be an entirely accruate way to gage
influence exerted by a paper on the literature of a field.  Even where
simple citation counts are employed, the time-delay in actual impact
in fields like mathematics make this type of metric unreliable.  Adler
concludes with a survey of common metrics and how they can be used and
misused.

Building on this notion of accuracy, the present work proposes an
approach which looks beyond the simple presence or absence of
citations.  By analyzing the texts of citing and cited documents, the
goal is to build a model which will indicate the strength of influence
exerted by a given paper or collection of papers.  In addition, the
proposed analysis techniques seeks to provide a method by which the
contributions of the author of a citing document can be evaluated.
This is allows the model to evaluate the original impact of an author,
that is to gauge how much original thought an author contributes to
the overall corpus of documents. 

\subsection{Proposed Influence Model}
The proposed model of influence is based on two parts.  First, the
present work will model documents as tensors which model the text of
both citing and cited documents. These tensors will the be decomposed
into rank 1 components which will then be compared for similarity.
The similarities between factors of cited documents and corresponding
factors of the citing document is used to assign weights to each
factor, and by extension to the document comprised of these factors.
These weights comprise the second part of the model where influence of
cited documents is used to explain the compositon of the citing
document.  The residuals of this model are interpreted as the citing
author's original contribution to the citing document. The proposed
model is sumarized in equation (\ref{eq:model}). 

\begin{equation}
    \label{eq:model}
    C = \sum w_id_i + w_a A
\end{equation}

Here, $C$ is the tensor representation of the citing document.
Individual cited documents $d_i$ are assigned weights $w_i$.  Finally,
the tensor representing author contribution $A$ is assigned weight
$w_a$.  

\subsection{Related Work}

\section{Approach}
\subsection{Tensors and Decomposition}
The term {\em tensor} carries several different definitions depending
on the field in which it is used.  For the purposes of the present
work, the term {\em tensor} will refer to a multi-dimensional array.
The objective of the tensor models constructed in this approach is to
decompose the tensor into explanatory factors.  Many methods for this
decomposition exist, but the most commonly applied decomposition is
the parallel factors (PARAFAC) decomposition first proposed by by
Harshman in 1970 \cite{harshman1970}.  In PARAFAC, a tensor is
decomposed into a set of factors consisting of rank 1 tensors.  The
decomposition is carried out to satisfy the following equation:

\begin{equation}
    \label{eq:parafac}
    T = \displaystyle\sum_{i=1}^{r} F_i + E
\end{equation}

where $F$ is the set of $r$ rank-1 tensors and $E$ is the error
residual of the model.  Naturally, the ALS algorithm seeks to minmize
the size of $E$.  It is also often convenient to express the factor
tensors in the form of vectors of each component such that the outer
product of these vectors forms the factor.  For instance,
a PARAFAC decomposition of a 3-way tensor can be written as:
\begin{equation}
    \label{eq:parafac-comp}
    T = \displaystyle\sum_{i=1}^{r} A_i \circ B_i \circ C_i + E
\end{equation}

A final common decomposition technique is to normalize the matricies
of the factors giving the final model's representation of:
\begin{equation}
    \label{eq:parafac-lambda}
    T = \displaystyle\sum_{i=1}^{r} \lambda_i A_i \circ B_i \circ C_i
    + E
\end{equation}

Here, the set $\lambda$ indicates the strength of the influence of
each explanatory factor, and so it is often helpful to list factors
such that $\lambda_1 \geq \lambda_2 \geq \ldots \lambda_r$.

PARAFAC is a constrained instance of the Tucker decomposition model,
which in turn is a further constrained principle component analysis
(PCA) deconstruction \cite{bro1997}.  Where a PARAFAC model fits, the
other models will fit as well or better.  However, PARAFAC carries
with it several advantages.  First, it is relatively easy to compute
using alternating least squares regression.  Second, it is unique
under rotation given a suffeciently large number of sought factors
\cite{harsman1970}.  But, perhaps most importantly, PARAFAC
decompositions typically can be interpreted intuitively.  

\subsection{Document Model}
\subsection{Influence Model}

\section{Example Problem}
\subsection{Test Set Creation}
\subsection{Results}

\section{Proposed Contributions}
\subsection{Influence Model}
\subsection{Filtering}
\subsection{Software}

\section{Bibliography}
\bibliography{sources}{}
\bibliographystyle{plain}

\end{document}
